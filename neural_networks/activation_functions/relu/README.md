# ReLU rectified linear unit

**ReLU** is simple and very strong activation function! It's **_standard_** equation is very easy:

![Relu equation](resources/relu.png?raw=true)

![Relu plot](resources/relu_plot.png?raw=true)

Sometimes we don't want to deny all negative values into zeros. We use **Leaky ReLU** or **Parametric ReLU**.

### Leaky ReLU

![LReLU equation](resources/lrelu.png?raw=true)

![LRelu plot](resources/lrelu_plot.png?raw=true)

### Parametric ReLU

![PReLU equation](resources/prelu.png?raw=true)

Where **alpha** is hyperparameter to tune!

![PRelu plot](resources/prelu_plot.png?raw=true)
