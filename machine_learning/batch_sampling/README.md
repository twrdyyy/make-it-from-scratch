# Batch sampling

<<<<<<< HEAD
With **batch sampling** we feed our model not with the whole training dataset but with small **samples** of it.
Often **samples** have size (**batch_size**) equal to N^th power of **2** e.g. **32**, **64**.
=======
With **batch sampling** we feed our model not with the whole training dataset but with small **samples** of it. 
Often **samples** have size (**batch_size**) equal to N^th power of **2** e.g. **32**, **64**.

This is implementation of python **generator** that takes whole training dataset and **yields** dataset samples of given size.
>>>>>>> c0c4502eeddc1fe198ed4b7219b729cb776ced7a
